{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"HR_comma_sep.csv\")\n",
    "data.head(10)\n",
    "y, X = dmatrices('left~satisfaction_level+last_evaluation+number_project+average_montly_hours+time_spend_company+Work_accident+promotion_last_5years+C(sales)+C(salary)', data, return_type='dataframe')\n",
    "X = np.asmatrix(X)\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "for i in range(1, X.shape[1]):\n",
    "    xmin = X[:,i].min()\n",
    "    xmax = X[:,i].max()\n",
    "    X[:, i] = (X[:, i] - xmin) / (xmax - xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xvali,ytrain,yvali=train_test_split(X, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=0 loss=1.125338568267821 error=0.5052087673972832 error_vali=0.49766666666666665\n",
      "T=5 loss=0.5487248908520651 error=0.24918743228602383 error_vali=0.24866666666666667\n",
      "T=10 loss=0.5043810358552849 error=0.23718643220268357 error_vali=0.23833333333333334\n",
      "T=15 loss=0.48342576427505307 error=0.22626885573797817 error_vali=0.228\n",
      "T=20 loss=0.46966024320936456 error=0.2187682306858905 error_vali=0.22033333333333333\n",
      "T=25 loss=0.46010838117706304 error=0.2173514459538295 error_vali=0.22066666666666668\n",
      "T=30 loss=0.45297590886796885 error=0.2137678139844987 error_vali=0.21666666666666667\n",
      "T=35 loss=0.44783827517044894 error=0.2173514459538295 error_vali=0.21966666666666668\n",
      "T=40 loss=0.44403288633042387 error=0.2115176264688724 error_vali=0.213\n",
      "T=45 loss=0.44119914749615574 error=0.21360113342778564 error_vali=0.216\n",
      "T=50 loss=0.43903299855922373 error=0.20910075839653305 error_vali=0.21233333333333335\n",
      "T=55 loss=0.4373425225124252 error=0.20960080006667223 error_vali=0.215\n",
      "T=60 loss=0.4359976341739453 error=0.2072672722726894 error_vali=0.21233333333333335\n",
      "T=65 loss=0.43491076333937717 error=0.20626718893241103 error_vali=0.212\n",
      "T=70 loss=0.4340206117280259 error=0.20601716809734144 error_vali=0.21033333333333334\n",
      "T=75 loss=0.4332830223667349 error=0.20626718893241103 error_vali=0.20933333333333334\n",
      "T=80 loss=0.4326654485236592 error=0.2056004667055588 error_vali=0.209\n",
      "T=85 loss=0.43214346828338424 error=0.2053504458704892 error_vali=0.208\n",
      "T=90 loss=0.4316984898857802 error=0.20435036253021086 error_vali=0.20766666666666667\n",
      "T=95 loss=0.43131617573490905 error=0.2036003000250021 error_vali=0.20766666666666667\n",
      "T=100 loss=0.4309853382329508 error=0.20410034169514127 error_vali=0.20866666666666667\n",
      "T=105 loss=0.43069715187740054 error=0.20410034169514127 error_vali=0.20833333333333334\n",
      "T=110 loss=0.43044458409061687 error=0.20401700141678472 error_vali=0.207\n",
      "T=115 loss=0.4302219787865045 error=0.20368364030335862 error_vali=0.20666666666666667\n",
      "T=120 loss=0.43002474812310193 error=0.20401700141678472 error_vali=0.208\n",
      "T=125 loss=0.42984914165046606 error=0.20435036253021086 error_vali=0.208\n",
      "T=130 loss=0.42969207148227256 error=0.20460038336528044 error_vali=0.20866666666666667\n",
      "T=135 loss=0.4295509784684717 error=0.20485040420035003 error_vali=0.209\n",
      "T=140 loss=0.429423728716468 error=0.20435036253021086 error_vali=0.20866666666666667\n",
      "T=145 loss=0.4293085328222652 error=0.20401700141678472 error_vali=0.209\n",
      "T=150 loss=0.4292038822769122 error=0.20376698058171513 error_vali=0.209\n",
      "T=155 loss=0.4291084989939231 error=0.20351695974664555 error_vali=0.209\n",
      "T=160 loss=0.4290212949560401 error=0.2036003000250021 error_vali=0.209\n",
      "T=165 loss=0.42894133973589094 error=0.20368364030335862 error_vali=0.21\n",
      "T=170 loss=0.42886783419378294 error=0.2039336611384282 error_vali=0.21\n",
      "T=175 loss=0.4288000890582121 error=0.20368364030335862 error_vali=0.21033333333333334\n",
      "T=180 loss=0.4287375073928463 error=0.20368364030335862 error_vali=0.21033333333333334\n",
      "T=185 loss=0.4286795701764878 error=0.2036003000250021 error_vali=0.21033333333333334\n",
      "T=190 loss=0.42862582439111746 error=0.20351695974664555 error_vali=0.21\n",
      "T=195 loss=0.42857587314123846 error=0.20376698058171513 error_vali=0.21066666666666667\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "alpha = 5 # learning rate\n",
    "beta = np.random.randn(Xtrain.shape[1]) # 随机初始化参数beta\n",
    "error_rates_train=[]\n",
    "error_rates_vali=[]\n",
    "for T in range(200):\n",
    "    prob = np.array(1. / (1 + np.exp(-np.matmul(Xtrain, beta)))).ravel()  # 根据当前beta预测离职的概率\n",
    "    prob_y = list(zip(prob, ytrain))\n",
    "    loss = -sum([np.log(p) if y == 1 else np.log(1 - p) for p, y in prob_y]) / len(ytrain) # 计算损失函数的值\n",
    "    error_rate = 0\n",
    "    for i in range(len(ytrain)):\n",
    "        if ((prob[i] > 0.5 and ytrain[i] == 0) or (prob[i] <= 0.5 and ytrain[i] == 1)):\n",
    "            error_rate += 1;\n",
    "    error_rate /= len(ytrain)\n",
    "    error_rates_train.append(error_rate)\n",
    "    \n",
    "    prob_vali = np.array(1. / (1 + np.exp(-np.matmul(Xvali, beta)))).ravel()  # 根据当前beta预测离职的概率\n",
    "    prob_y_vali = list(zip(prob_vali, yvali))\n",
    "    loss_vali = -sum([np.log(p) if y == 1 else np.log(1 - p) for p, y in prob_y_vali]) / len(yvali) # 计算损失函数的值\n",
    "    error_rate_vali = 0\n",
    "    for i in range(len(yvali)):\n",
    "        if ((prob_vali[i] > 0.5 and yvali[i] == 0) or (prob_vali[i] <= 0.5 and yvali[i] == 1)):\n",
    "            error_rate_vali += 1\n",
    "    error_rate_vali /= len(yvali)\n",
    "    error_rates_vali.append(error_rate_vali)\n",
    "    \n",
    "    if T % 5 ==0 :\n",
    "        print('T=' + str(T) + ' loss=' + str(loss) + ' error=' + str(error_rate)+ ' error_vali=' + str(error_rate_vali))\n",
    "    # 计算损失函数关于beta每个分量的导数\n",
    "    deriv = np.zeros(Xtrain.shape[1])\n",
    "    for i in range(len(ytrain)):\n",
    "        deriv += np.asarray(Xtrain[i,:]).ravel() * (prob[i] - ytrain[i])\n",
    "    deriv /= len(ytrain)\n",
    "    # 沿导数相反方向修改beta\n",
    "    beta -= alpha * deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(50,200), error_rates_train[50:], 'r^', range(50, 200), error_rates_vali[50:], 'bs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We calculated 0.3306924011046167\n",
      "According to definition of gradient, it is 0.33069903233373665\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "alpha = 1  # learning rate\n",
    "beta = np.random.randn(X.shape[1]) # 随机初始化参数beta\n",
    "\n",
    "#dF/dbeta0\n",
    "prob = np.array(1. / (1 + np.exp(-np.matmul(X, beta)))).ravel()  # 根据当前beta预测离职的概率\n",
    "prob_y = list(zip(prob, y))\n",
    "loss = -sum([np.log(p) if y == 1 else np.log(1. - p) for p, y in prob_y]) / len(y) # 计算损失函数的值\n",
    "deriv = np.zeros(X.shape[1])\n",
    "for i in range(len(y)):\n",
    "    deriv += np.asarray(X[i,:]).ravel() * (prob[i] - y[i])\n",
    "deriv /= len(y)\n",
    "print('We calculated ' + str(deriv[0]))\n",
    "\n",
    "delta = 0.0001\n",
    "beta[0] += delta\n",
    "prob = np.array(1. / (1 + np.exp(-np.matmul(X, beta)))).ravel()  # 根据当前beta预测离职的概率\n",
    "prob_y = list(zip(prob, y))\n",
    "loss2 = -sum([np.log(p) if y == 1 else np.log(1. - p) for p, y in prob_y]) / len(y) # 计算损失函数的值\n",
    "shouldbe = (loss2 - loss) / delta # (F(b0+delta,b1,...,bn) - F(b0,...bn)) / delta\n",
    "print('According to definition of gradient, it is ' + str(shouldbe))\n",
    "if shouldbe == deriv[0]:\n",
    "    print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
